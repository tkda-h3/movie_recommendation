{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "dir_name = './ml-100k/'\n",
    "# read the number of users and items\n",
    "f = open(dir_name + 'u.info')\n",
    "user_num, item_num = [(int)(li.split(\" \")[0]) for li in f.readlines()[:-1]]\n",
    "f.close()\n",
    "\n",
    "# read ratings\n",
    "R = np.zeros((user_num,item_num))\n",
    "print R.shape\n",
    "f = open(dir_name + 'u.data')\n",
    "lines = [map(lambda x: int(x), li.split(\"\\t\")[:-1]) for li in f.readlines()]\n",
    "f.close()\n",
    "for li in lines:\n",
    "    R[li[0]-1,li[1]-1] = li[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "誤差関数は以下の通り\n",
    "\\begin{equation*} \\min_{p,q,b_u,b_i} \\sum_{(u,i) \\in R} (r_{u,i} - p_u q^{T}_i - \\mu - b_u - b_i)^{2} + \\lambda (\\|p\\|^{2} + \\|q\\|^{2}  + b^{2}_u + b^{2}_i)\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy_score(ans,pred):\n",
    "    \"\"\"\n",
    "    要素が0以外の正解率を計算\n",
    "    \"\"\"\n",
    "    cmp_num = (ans != 0).sum() # ansの0でない要素の数\n",
    "    mistake_num = (pred * (ans != 0) != ans).sum() #ansの０以外の要素のうちpredと不一致の数\n",
    "    return (cmp_num - mistake_num) / float(cmp_num)\n",
    "\n",
    "def cost_func(R,P,Q,mu,b_u,b_i,lamb):\n",
    "    \"\"\"\n",
    "    return error fucntion\n",
    "    \"\"\"\n",
    "    sigma = np.sum(((R - mu - b_u[:,np.newaxis] - b_i[np.newaxis,:] - np.dot(P,Q.T))*(R != 0))**2)#二乗誤差\n",
    "    cost = sigma + (lamb/2) * (np.sum(b_i**2) + np.sum(b_u**2) + np.linalg.norm(P) + np.linalg.norm(Q))\n",
    "    return cost\n",
    "\n",
    "def matrix_factorization(R,latent_dim = 20,alpha=0.005,lamb=0.03):\n",
    "    \"\"\"\n",
    "    R : 2-D np.array (the number of Users, the number of Items)\n",
    "    latent_dim : the number of latent dimention \n",
    "    alpha : the learning rate of SGD\n",
    "    lamb : regularization parameter\n",
    "    \"\"\"\n",
    "    #split data\n",
    "    test_R = R[:R.shape[0]/2, :R.shape[1]/2].copy()    \n",
    "    R[:R.shape[0]/2, :R.shape[1]/2] = 0\n",
    "    \n",
    "    # initialize parameter\n",
    "    low = 0.1\n",
    "    high = 0.5\n",
    "    P = np.random.uniform(low=low,high =high,size=(R.shape[0],latent_dim))\n",
    "    Q = np.random.uniform(low=low,high =high,size=(R.shape[1],latent_dim))\n",
    "    mu = R.sum() / (R != 0).sum() #  the average rating over all items\n",
    "    b_u = np.random.uniform(low=low, high=high,size=(R.shape[0])) # assume the average rating of each user - mu\n",
    "    b_i = np.random.uniform(low=low,high=high,size=(R.shape[1])) # assume the average rating of each item - mu\n",
    "    \n",
    "    #train and test\n",
    "    for epoch in xrange(300):  \n",
    "        for i,j in np.argwhere(R != 0):# i: user ID, j: Item ID\n",
    "            err = R[i,j] - np.dot(P[i],Q[j].T) - mu - b_u[i] - b_i[j] \n",
    "            #update(SGD)\n",
    "            b_u[i] += alpha*(err - lamb*b_u[i])\n",
    "            b_i[j] += alpha*(err - lamb*b_i[j])\n",
    "            Q[j] += alpha*(err*P[i] - lamb*Q[j])            \n",
    "            P[i] += alpha*(err*Q[j] - lamb*P[i])\n",
    "        #test\n",
    "        train_cost = cost_func(R,P,Q,mu,b_u,b_i,lamb)\n",
    "        pred = np.around(np.dot(P,Q.T)+ mu + b_u[:,np.newaxis] + b_i[np.newaxis,:]).astype(\"int8\")\n",
    "        test_cost = cost_func(R[:R.shape[0]/2, :R.shape[1]/2],P[:R.shape[0]/2],Q[:R.shape[1]/2],mu,b_u[:R.shape[0]/2],b_i[:R.shape[1]/2],lamb)\n",
    "        if (epoch+1) % 20 == 0 or epoch == 0:\n",
    "            print \"epoch: %s, train cost: %.3f, train accuracy : %.3f, test cost: %.3f, test accuracy: %.3f\" \\\n",
    "                % (epoch+1, train_cost, accuracy_score(R,pred), test_cost, accuracy_score(test_R,pred[:R.shape[0]/2, :R.shape[1]/2]))\n",
    "            \n",
    "        \n",
    "    return pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train cost: 119814.368, train accuracy : 0.266, test cost: 3.234, test accuracy: 0.220\n",
      "epoch: 20, train cost: 32389.288, train accuracy : 0.483, test cost: 4.556, test accuracy: 0.342\n",
      "epoch: 40, train cost: 16977.212, train accuracy : 0.628, test cost: 4.912, test accuracy: 0.356\n",
      "epoch: 60, train cost: 10374.159, train accuracy : 0.752, test cost: 4.984, test accuracy: 0.357\n",
      "epoch: 80, train cost: 7579.391, train accuracy : 0.826, test cost: 4.971, test accuracy: 0.355\n",
      "epoch: 100, train cost: 6188.980, train accuracy : 0.865, test cost: 4.929, test accuracy: 0.351\n",
      "epoch: 120, train cost: 5395.588, train accuracy : 0.887, test cost: 4.879, test accuracy: 0.349\n",
      "epoch: 140, train cost: 4895.185, train accuracy : 0.901, test cost: 4.831, test accuracy: 0.347\n",
      "epoch: 160, train cost: 4556.067, train accuracy : 0.911, test cost: 4.787, test accuracy: 0.346\n",
      "epoch: 180, train cost: 4313.713, train accuracy : 0.917, test cost: 4.748, test accuracy: 0.344\n",
      "epoch: 200, train cost: 4133.248, train accuracy : 0.922, test cost: 4.714, test accuracy: 0.343\n",
      "epoch: 220, train cost: 3994.363, train accuracy : 0.925, test cost: 4.685, test accuracy: 0.343\n",
      "epoch: 240, train cost: 3884.529, train accuracy : 0.928, test cost: 4.660, test accuracy: 0.343\n",
      "epoch: 260, train cost: 3795.659, train accuracy : 0.931, test cost: 4.639, test accuracy: 0.342\n",
      "epoch: 280, train cost: 3722.332, train accuracy : 0.932, test cost: 4.621, test accuracy: 0.342\n",
      "epoch: 300, train cost: 3660.797, train accuracy : 0.934, test cost: 4.606, test accuracy: 0.342\n"
     ]
    }
   ],
   "source": [
    "pred = matrix_factorization(R.copy() ,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
